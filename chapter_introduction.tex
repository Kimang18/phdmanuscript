\chapter{Introduction}
\label{chapter:introduction}

\begin{itemize}
    \item context introduction
    \item gentle problem presentation
    \item results: discounted problem, non-discounted problem
\end{itemize}

\section{Topic of the thesis}

\section{Motivation for Markovian bandit}

\begin{itemize}
    \item recent applications: queuing systems,...
    \item efficient index policy computation
    \item curse of dimensionality in reinforcement learning algorithms
\end{itemize}

\section{Outline of the thesis}

\begin{enumerate}
    \item Part 1 Background: about Markov decision process and reinforcement learning
    \item Part 2 Indexability: Markovian bandit and our first contribution
    \item Part 3 Learning in Markovian bandit: rested MB and restless MB
\end{enumerate}

Chapter~\ref{ch:mdp}, \ref{ch:mb_problem} are required to understand our contribution in Chapter~\ref{ch:index_computation}.
Chapter~\ref{ch:mdp}, \ref{ch:mb_problem}, and \ref{ch:rl} are required to understand our contribution in Chapter~\ref{ch:learning_rested} and \ref{ch:learning_restless}.

We suggest the following flow of reading: start with Chapter~\ref{ch:mdp} and \ref{ch:mb_problem}, then Chapter~\ref{ch:index_computation}. Next, jump back to Chapter~\ref{ch:rl}. Finally, finish Part~\ref{part:learning} and the conclusion.

%To introduce my work, I will write a nice introduction in the following.
%Citation example for the Top500 website~\cite{top500} and some random paper~\cite{graham1969}.
%
%\section{Hello World}
%\lipsum[1-5]
