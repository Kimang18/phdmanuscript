\chapter{Introduction}
\label{chapter:introduction}

\begin{itemize}
    \item context introduction
    \item gentle problem presentation
    \item results: discounted problem, non-discounted problem
\end{itemize}

\section{Topic of the thesis}

\section{Motivation for Markovian bandit}

\begin{itemize}
    \item recent applications: queuing systems,...
    \item efficient index policy computation
    \item curse of dimensionality in reinforcement learning algorithms
\end{itemize}

\section{Outline of the thesis}

\begin{enumerate}
    \item Part 1 Background: about Markov decision process and reinforcement learning
    \item Part 2 Indexability: Markovian bandit and our first contribution
    \item Part 3 Learning in Markovian bandit: rested MB and restless MB
\end{enumerate}

Multi-armed bandit is a well-known sequential decision problem in Artificial Intelligence literature.

%To introduce my work, I will write a nice introduction in the following.
%Citation example for the Top500 website~\cite{top500} and some random paper~\cite{graham1969}.
%
%\section{Hello World}
%\lipsum[1-5]
