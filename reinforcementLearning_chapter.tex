\chapter{Reinforcement Learning}
\label{ch:rl_finite_horizon}

\section{Problem Formulation}

\subsection{Finite-Horizon}


\subsection{Infinite-Horizon}


\section{Regret}
\label{sec:regret}

    In general, in MDP $M=\langle\mSpace,\aSpace,r,P,H\rangle$, the agent starts to play from state $x$ with a certain probability given by the distribution $\rho(x)$. When using the algorithm $\Algo$ to play for $T$ time steps, the incurring regret is given by
    \begin{align}
        \Reg(T,\Algo,M)=\sum_{k=1}^{\lceil T/H\rceil}\sum_{x\in\mcal{E}}\rho(x)\big(V_{M,1}^*(x) -V_{M,1}^{\pik}(x)\big) =\sum_{k=1}^{\lceil T/H\rceil}\sum_{x\in\mcal{E}}\rho(x)\Delta_k(x)
    \end{align}
    where, during $k$th episode, $\Algo$ follows policy $\pik$ which is optimal in the imaginary MDP $\Mk$, $V^*_{M,1}(x)$ and $V_{M,1}^{\pik}(x)$ are the value of state $x$ under the optimal policy and the policy $\pik$ starting from time step $1$ to $H$ respectively, and $H$ is the horizon of each episode.
    Note that we write $V_M$ as the value evaluated using the real MDP $M$ and $V_{\Mk}$ as the one evaluated using the imaginary MDP $\Mk$. It is convenient to seperate the regret gap into two gaps as the following:
    \begin{enumerate}
        \item the regret gap at $k$th episode:
        \begin{align*}
        \Delta_k &=V_{M,1}^* -V_{M,1}^{\pik} \\
        &=\big(V^*_{M,1} -V^{\pik}_{\Mk,1}\big) +\big(V^{\pik}_{\Mk,1} -V_{M,1}^{\pik}\big) \\
        &=\Delta_k^{opt}+\Delta_k^{conc}
        \end{align*}
    \item the gap from optimism $\Delta_k^{opt}(x)=V^*_{M,1}(x) -V^{\pik}_{\Mk,1}(x)$, where $V^{\pik}_{\Mk,1}(x)$ is the value of state $x$ under the policy $\pik$ from time step $1$ to $H$ and evaluated in the imagined MDP $\Mk$
    \item the gap from concentration $\Delta_k^{conc}(x)=V^{\pik}_{\Mk,1}(x) -V_{M,1}^{\pik}(x)$.
    \end{enumerate}
    So,
    \begin{equation}
    \label{eq:eq_6}
    \Reg(T,\Algo,M)= \sum_{k=1}^{\lceil T/H\rceil}\sum_{x\in\mcal{E}}\rho(x)(\Delta_k^{opt}(x)+\Delta_k^{conc}(x))
    \end{equation}

\section{UCRL2}
\label{sec:ucrl2}

    \subsection{Optimism in Face of Uncertainty(OFU)}
    \label{subsec:OFU}
    
    This algorithm uses the principle of "Optimism in Face of Uncertainty": when we are \textbf{uncertain} about the outcome, we consider the \textit{best possible world} and choose the \textit{best decision} in imaginary world. Let $\mcal{O}_k$ be the set of observations collected until the beginning of episode $k$. UCRL2 does
        \begin{enumerate}
            \item \label{it:ucrl2_1} compute a set of plausible MDPs, $\mcal{M}_k$, based on the observations $\mcal{O}_k$ at the beginning of episode $k$. This set contains the unknown MDP $M$ with high probability (this is equivalent to compute the sets $\mcal{R}_k$ and $\mcal{P}_k$ containing $r$ and $P$ respectively with high probability)
            \item compute $\pik$ such that
                \begin{align}
                    V_{\Mk,1}^{\pik} \ge \max_{\pi}\max_{\Mbar\in\mcal{M}_k} V_{\Mbar,1}^\pi
                \end{align}
            \item follow $\pik$ during the episode $k$
            \item after finishing episode $k$, update $\mcal{O}_{k+1}$ and go back to \ref{it:ucrl2_1}
        \end{enumerate}
    
    \subsection{High Probability Event}
    \label{subsec:high_prob_event}
        In order to build the sets $\mcal{R}$ and $\mcal{P}$, we should review some inequalities that are vital to our construction.
    
        \begin{thm}[Hoeffding inequality]
        \label{thm:hoeffding}
            Let $\{R_i\}_{i\le n}$ be independent and identically distributed random variable with mean $r$ bounded in $[0,1]$.
            By Hoeffding inequality,
            \begin{align*}
                \proba{\Big\vert\frac{1}{n}\sum_{i=1}^nR_i-r\Big\vert>\ep}\le2\exp\left(-2n\ep^2\right)
            \end{align*}
            The random variables $\{R_i\}_{i\le n}$ bounded in $[0,1]$ are $(1/2)$-sub-Gaussian.
        \end{thm}
        \begin{thm}[Weissman inequality (Inequalities for L1 deviation of the empirical distribution)]
        \label{thm:weissman}
            Let $\{Y_i\}_{i\le n}$ be $n$ i.i.d sample from a distribution $P$ over a finite set $\mSpace=\{1,\dots,\mSize\}$. Define the empirical distribution $\Pbar(y)=\frac{1}{n}\sum_{i=1}^{n}\mathbb{I}_{Y_i=y}, \forall y\in\mSpace$. Then, for any $\ep>0$,
            \begin{align*}
                \proba{\Vert\Pbar-P\Vert_1> \ep} \le 2^\mSize\exp\left(-\frac{n\ep^2}{2}\right)
            \end{align*}
        \end{thm}
        
        At time $t$, let $\rbar_t$ and $\Pbar_t$ be the empirical estimators of $r$ and $P$ respectively.
        Let $N_t(x,a)$ be the number of visits to state-action pair $(x,a)$ up to time $t$.
        We have
        \begin{align*}
            \rbar_t(x,a) =\frac1{N_t(x,a)}\sum_{h=1}^{t}R_h\I_{\{X_h=x\wedge A_h=a\}} \text{ and } \Pbar_t(x,a,y) =\frac1{N_t(x,a)}\sum_{h=1}^{t}\I_{\{X_h=x\wedge A_h=a\wedge X_{h+1}=y\}}
        \end{align*}

        Now, we prove a high probability event:
        \begin{lem}
        \label{lem:high_prob_event}
            Let $L_t:=\sqrt{2\log(4EAt/\delta)}$. Then, the event
            \begin{align}
            \event_t:=\bigg\{\forall a\in\mcal{A}, \forall x\in\mcal{E}, t'\le t: &\vert\rbar_{t'}(x,a)-r(x,a)\vert\le \frac{L_t}{2\sqrt{N_{t'}(x,a)}}\\
            \text{ and } &\Vert\Pbar_{t'}(x,a)-P(x,a)\Vert_1\le \frac{L_t+1.5\sqrt{E}}{\sqrt{N_{t'}(x,a)}}\bigg\}
            \end{align}
            is true with probability $1-\delta$.
        \end{lem}
        \begin{proof}
            By Theorem~\ref{thm:hoeffding}, for any $\ep>0$, one has
            \begin{align*}
            \proba{\vert\rbar_{t}(x,a)-r(x,a)\vert>\ep \mid N_{t}(x,a)} \le 2\exp\left(-2N_{t}(x,a)\ep^2\right)
            \end{align*}
            This holds for $\ep=\sqrt{\frac{\log(4EAt/\delta)}{2N_t(x,a)}}$ where $0<\delta<1$.
            As $N_t(x,a)\le t$, by using the union-bound, this implies that
            \begin{align}
            &\proba{\exists x,a, t'\le t: \vert\rbar_{t'}(x,a)-r(x,a)\vert>\sqrt{\frac{\log(4EAt/\delta)}{2N_{t'}(x,a)}}} \label{eq:conc_r}\\
            &\qquad \le \sum_{t'=1}^{t}\sum_{x,a} \proba{\vert\rbar_{t'}(x,a)-r(x,a)\vert>\sqrt{\frac{\log(4EAt/\delta)}{2N_{t'}(x,a)}}} \nonumber \\
            &\qquad \le \sum_{t'=1}^{t}\sum_{x,a} 2\exp\left(-2N_{t'}(x,a)\times\frac{\log(4EAt/\delta)}{2N_{t'}(x,a)}\right) =2EAt \frac{\delta}{4EAt}=\frac{\delta}2 \nonumber
            \end{align}
            By Theorem~\ref{thm:weissman}, for any $\ep>0$, one has
            \begin{align*}
            \proba{\Vert\Pbar_t(x,a)-P(x,a)\Vert_1 > \ep \mid N_t(x,a)} \le 2^E\exp\left(-\frac{N_t(x,a)\ep^2}{2}\right)
            \end{align*}
            Similarly, with $\ep=\sqrt{2\log(2EAt2^E/\delta)/N_t(x,a)}$, we have
            \begin{align*}
            &\proba{\exists x,a, t'\le t: \Vert\Pbar_t(x,a)-P(x,a)\Vert_1 >\sqrt{\frac{2\log(2EAt2^E/\delta)}{N_{t'}(x,a)}}} \\
            &\qquad \le 2^EEAt\exp\left(-\frac{N_t(x,a)}{2}\times\frac{2\log(2EAt2^E/\delta)}{N_{t'}(x,a)}\right) =\frac{\delta}2
            \end{align*}
            Since $L_t=\sqrt{2\log(4EAt/\delta)}$ and $\sqrt{x+y}\le\sqrt{x}+\sqrt{y}$, we have $\sqrt{2\log(2EAt2^E/\delta)}=\sqrt{2\log(4EAt/\delta) +2(E-1)\log2}\le L_t + \sqrt{2(E-1)\log2} \le L_t +1.5\sqrt{E}$.
            Hence,
            \begin{align}
            \label{eq:conc_p}
            \proba{\exists x,a, t'\le t: \Vert\Pbar_t(x,a)-P(x,a)\Vert_1 >\frac{L_t+1.5\sqrt{E}}{\sqrt{N_{t'}(x,a)}}} \le \frac{\delta}2
            \end{align}
            The complement of event $\event_t$ defined in the statement of Lemma~\ref{lem:high_prob_event} is the union of \eqref{eq:conc_r} and \eqref{eq:conc_p}.
            Hence, the union-bound concludes the proof of the lemma.
        \end{proof}

\subsection{Regret bound}
\label{subsec:regret_ucrl2}

%TOCONTINUE
    Let $t_k:=(k-1)H+1$ and $L_{t_k}=\sqrt{2\log(4EAt_k/\delta)}$.
    Define the set of plausible MDPs by
    \begin{align*}
        \mcal{M}_k :=\left\{(r_k,P_k) \colon \forall x,a, \vert r_k(x,a)-\rbar_k(x,a)\vert \le \frac{L_{t_k}}{2\sqrt{N_k(x,a)}} \text{ and }\right. \\
        \left. \Vert P_k(x,a)-\Pbar_k(x,a)\Vert_1\le \frac{L_{t_k}+1.5\sqrt{E}}{\sqrt{N_k(x,a)}}\right\}.
    \end{align*}
    So, under event $\event_k$, the unknown MDP $M$ belongs to $\mcal{M}_k$.
    By the definition of $\pik$, $\Delta_k^{opt}=V^*_{M,1}(x) -V^{\pik}_{\Mk,1}(x)\le0$.
    Then, under event $\event_k$,
    \begin{align*}
        \sum_{k=1}^{\lceil T/H\rceil}\Delta_k \le \sum_{k=1}^{\lceil T/H\rceil}\Delta_k^{conc}.
    \end{align*}
    
    \subsubsection{Gap from concentration}
    \label{subsubsec:sec_gap_conc}
    
        Let $a_{kh}=\pik(x_{kh})$ be the action that policy $\pik$ takes when at state $x_{kh}$ at time step $h$ in episode $k$. From Bellman's equation, we have
        \begin{align*}
            V^{\pik}_{M,H}(x_{k1})
            &= r^{\pik}(x_{k1}) +\sum_{y\in\mSpace}P^{\pik}(x_{k1},y)V^{\pik}_{M,H-1}(y)
        \end{align*}
        In vector form, we have
        \begin{align*}
            V^{\pik}_{M,H} &= r^{\pik} +P^{\pik}V^{\pik}_{M,H-1} \\
            V^{\pik}_{M_k,H} &= r^{\pik}_k +P^{\pik}_kV^{\pik}_{M_k,H-1}.
        \end{align*}
        Then,
        \begin{align*}
            \Delta_k^{conc}
            &= V^{\pik}_{M_k,1} -V^{\pik}_{M,1} \\
            &= r^{\pik}_k-r^{\pik} +(P^{\pik}_k -P^{\pik})V^{\pik}_{M_k,2} +P^{\pik}(V^{\pik}_{M,2}-V^{\pik}_{M_k,2}).
        \end{align*}
        So, at state $x_{k1}$
        \begin{align*}
            \Delta_k^{conc}(x_{k1})
            &= r^{\pik}_k(x_{k1})-r^{\pik}(x_{k1}) +[(P^{\pik}_k(x_{k1},\cdot) -P^{\pik}(x_{k1},\cdot))V^{\pik}_{M_k,2}] \\
            &\qquad +\ex{V^{\pik}_{M,2}(Y)-V^{\pik}_{M_k,2}(Y) \mid Y\sim P^{\pik}(x_{k1},\cdot)} \\
            &\le \vert r^{\pik}_k(x_{k1}) -r^{\pik}(x_{k1})\vert +(H-1)\Vert P^{\pik}_k(x_{k1},\cdot) -P^{\pik}(x_{k1},\cdot)\Vert_1 \\
            &\qquad +\ex{V^{\pik}_{M,2}(Y)-V^{\pik}_{M_k,2}(Y) \mid Y\sim P^{\pik}(x_{k1},\cdot)}.
        \end{align*}
        Continue to rollout Bellman's equation for $V^{\pik}_{M_k,h}-V^{\pik}_{M,h}$ with $2\le h\le H$, we get
        %TOCONTINUE
        \begin{align*}
            \ex{\Delta_k^{conc}} \le \sum_{h=1}^{H}\vert r_k-r\vert(x_{kh},a_{kh}) +(H-1)\Vert P_k -P\Vert_1(x_{kh},a_{kh}).
        \end{align*}
        Now,
        \begin{align*}
            \sum_{k=1}^{\lceil T/H\rceil}\ex{\Delta_k^{conc}}
            &\le \sum_{k=1}^{\lceil T/H\rceil} \sum_{h=1}^{H}\vert r_k-r\vert(x_{kh},a_{kh}) +(H-1)\Vert P_k -P\Vert_1(x_{kh},a_{kh}) \\
            &=\sum_{k=1}^{\lceil T/H\rceil} \sum_{t=t_k}^{t_{k+1}-1}\vert r_k(x_t,a_t)-r(x_t,a_t)\vert +(H-1)\Vert P_k(x_t,a_t) -P(x_t,a_t)\Vert_1 \\
            &\overset{(a)}\le \sum_{k=1}^{\lceil T/H\rceil} \sum_{t=t_k}^{t_{k+1}-1} \frac{L_{t_k}}{2\sqrt{N_k(x_t,a_t)}} +(H-1)\frac{L_{t_k}+1.5\sqrt{E}}{\sqrt{N_k(x_t,a_t)}} \le\sum_{k=1}^{\lceil T/H\rceil} \sum_{t=t_k}^{t_{k+1}-1}H\frac{L_T+1.5\sqrt{E}}{\sqrt{N_k(x_t,a_t)}}
        \end{align*}
        where $(a)$ is true under event $\event_k$.
        For $t\le t_k$, let $\tilde{N}_t(x,a)$ be the real-time counter for state-action pair $(x,a)$. We have $\forall t\le T, \forall (x,a)\in \mdpStateSpace\times\ActionSpace$,
        
        \begin{align*}
            N_{\lfloor t/H\rfloor+1}(x,a) +\horizon \ge \tilde{N}_t(x,a) &\ge N_{\lfloor t/H\rfloor+1}(x,a) \ge 1 \\
            N_{\lfloor t/H\rfloor+1}(x,a) &\ge \max\{1, \tilde{N}_t(x,a) -\horizon\} \\
            \sum_{k=1}^{\lceil T/\horizon\rceil} \sum_{t=t_k}^{t_{k+1}-1} \frac{1}{\sqrt{N_{\lfloor t/H\rfloor+1}(x_t,a_t)}} &\le \sum_{k=1}^{\lceil T/\horizon\rceil} \sum_{t=t_k}^{t_{k+1}-1} \min\left\{1, \frac{1}{\sqrt{\tilde{N}_t(x_t,a_t) -\horizon}}\right\} \\
            \sum_{k=1}^{\lceil T/\horizon\rceil} \sum_{t=t_k}^{t_{k+1}-1} \frac{1}{\sqrt{N_k(x_t,a_t)}} &\le \sum_{t=1}^{T} \min\left\{1, \frac{1}{\sqrt{\tilde{N}_t(x_t,a_t) -\horizon}}\right\} \\
            &= \sum_{x,a} \sum_{t=1}^{\tilde{N}_T(x,a)} \min\left\{1, \frac{1}{\sqrt{t -\horizon}}\right\} \\
            &= \sum_{x,a} \Big(H +\sum_{t=H+1}^{\tilde{N}_T(x,a)} \frac{1}{\sqrt{t -H}}\Big) \\
            &= EAH +\sum_{x,a} \sum_{t=1}^{\tilde{N}_T(x,a) -\horizon} \frac{1}{\sqrt{t}} \\
            &\le EAH +\sum_{x,a} \int_0^{\tilde{N}_T(x,a) -\horizon} \frac{dt}{\sqrt{t}} \\
            &\le EAH +\sum_{x,a} \int_0^{\tilde{N}_T(x,a)} \frac{dt}{\sqrt{t}} \\
            &= EAH +2\sum_{x,a} \sqrt{\tilde{N}_T(x,a)} \\
            &\overset{(a)}\le EAH +2\sqrt{EA \sum_{x,a}\tilde{N}_T(x,a)} \\
            &= EAH +2\sqrt{EAT}
        \end{align*}
        where inequality $(a)$ is true by Jensen's inequality. Indeed, using Jensen's inequality, we have
        \begin{align*}
            \frac{1}{EA}\sum_{x,a}\sqrt{\tilde{N}_T(x,a)} \le\sqrt{\frac{1}{EA}\sum_{x,a}\tilde{N}_T(x,a)}.
        \end{align*}
        Thus,
        \begin{align*}
            \sum_{k=1}^{\lceil T/\horizon\rceil}\ex{\Delta_k^{conc}}
            &\le H\Big(L_T+1.5\sqrt{E}\Big) \Big(EAH +2\sqrt{EAT}\Big) \\
            &= H\Big(\sqrt{2\log(4EAT/\delta)} +1.5\sqrt{E}\Big) \Big(EAH +2\sqrt{EAT}\Big)
        \end{align*}
        Now,
        \begin{align*}
            \ex{\Delta_k}
            &=\ex{\Delta_k\I_{\event_k} +\Delta_k\I_{\neg\event_k}} \\
            &\le \ex{\Delta_k\I_{\event_k}} +H\proba{\neg\event_k} =\ex{\Delta_k\I_{\event_k}} +H\delta.
        \end{align*}
        Finally, the expected regret UCRL2 is bounded by
        \begin{align*}
            \ex{\Reg(T,\mathrm{UCRL2},M)} 
            &\le H\Big(\sqrt{2\log(4EAT/\delta)} +1.5\sqrt{E}\Big) \Big(EAH +2\sqrt{EAT}\Big) +\sum_{k=1}^{\lceil T/H\rceil}H\delta \\
            &\le H\Big(\sqrt{2\log(4EAT/\delta)} +1.5\sqrt{E}\Big) \Big(EAH +2\sqrt{EAT}\Big) +T\delta
        \end{align*}
        
        This result is a significant statistical guarantee as its scaling is close to the fundamental lower bound $\Omega(\sqrt{HEAT})$ \cite{jaksch2010near, osband2016lower}.

\section{UCBVI}
\label{sec:ucbvi}
    OFU algorithm presented above applies the confidence sets on the parameters of the model, namely $(r,P)$. Another approach from \cite{gheshlaghiazarMinimaxRegretBounds2017} is to directly apply the confidence set on the value function. One known algorithm is UCBVI that works as the following
    
    At the start of episode $k$,
    \begin{enumerate}
        \item compute the empirical reward and transition $(\rbar_k,\Pbar_k)$ for all state-action pairs
        \item set $V_{k,H+1}=0$
        \item for each time step $h=H,\dots,1$, compute the value and quality function for each $(x,a)$ state-action pairs:
        \begin{align*}
            Q_{k,h}(x,a) &=\min\left\{Q_{k-1,h}(x,a), H, \rbar_k(x,a) +\Pbar_k(x,a)V_{k,h+1} +b_k(x,a)\right\} \\
            V_{k,h}(x) &= \max_{a\in\ActionSpace}Q_{k,h}(x,a)
        \end{align*}
        \item during episode $k$, for each time step $h=1,\dots,H$, 
        \begin{align*}
            \pol_{k}(x_{kh}) =\arg\max_{a\in\ActionSpace}Q_{k,h}(x_{kh},a)=\Action_{kh}
        \end{align*}
    \end{enumerate}
    
    \subsection{High Probability Event}
    \label{subsec:high_prob_event}
    
        Let $L_t:=\log(4E^2At/\delta)$. For any deterministic mappings $f\colon \mcal{E}\mapsto[0,H-1]$, and any $g\colon\mcal{E}\mapsto[0,H]$, we define the following events:
        \begin{align}
            &\event_1:=\left\{\forall x, a, t'\le t,|\rhat_{t'}(x,a)-r(x,a)+[(\Phat_{t'}-P)f](x,a)| \le H\sqrt{\frac{L_t}{2N_{t'}(x,a)}}\right\} \\
            &\event_2:=\left\{\forall x, a, y, t'\le t,|\Phat_{t'}(x,a,y)-P(x,a,y)|g(y) \le\sqrt{\frac{2P(x,a,y)[1-P(x,a,y)]g^2(y)L_t}{N_{t'}(x,a)}} +\frac{2HL_t}{3N_{t'}(x,a)}\right\} \\
            &\event:=\event_1\cap\event_2.
        \end{align}
        
        \begin{lem}
        \label{lem:high_prob}
            For any deterministic mappings $f\colon \mcal{E}\mapsto[0,H-1]$ and $g\colon \mcal{E}\mapsto[0,H]$, we have $\proba{\event}\ge1-\delta$.
        \end{lem}
        \begin{proof}
        Given $\{U_i\}_{1\le i\le n}$ independent samples of random variable $U\in[0, c]$ where $c\in\R$, Theorem~\ref{thm:hoeffding} gives, for $\ep>0$,
        \begin{align*}
        \proba{|\bar{U}-\ex{U}|\ge \varepsilon} \le 2e^{-2\frac{n}{c^2}\varepsilon^2}
        \end{align*}
        Consider a fixed $(x,a)$.
        For any deterministic mapping $f\colon\mcal{E}\mapsto[0,H-1]$, let $U:=R+\beta f(Y)$ be a random variable where $R\in[0,1]$ and $Y\in\mcal{E}$ are random variables such that $\ex{R}=r(x,a)$ and $\proba{Y=y}=P(x,a,y)$.
        Hence, the expectation of $U$ is given by 
        \begin{align*}
        \ex{U}=r(x,a) +\sum_{y\in\mcal{E}}P(x,a,y)f(y)=r(x,a) +P(x,a)f.
        \end{align*}
        Also, $U\in [0,H]$.
        After $n$ of activations, we will have collected $\{U_i\}_{1\le i\le n}$.
        The empirical estimate of $U$ is
        $$\bar{U}:=\frac1n\sum_{i=1}^{n} U_i=\rbar(x,a) +\Pbar(x,a)f.$$
        Then,
        \begin{align*}
        &\proba{\vert\bar{U}-\ex{U}\vert >\varepsilon} \le2e^{-2\frac{n\varepsilon^2}{H^2}} \\
        &\proba{\vert \rbar(x,a)-r(x,a) +(\Pbar(x,a) -P(x,a))f\vert >\varepsilon} \le2e^{-2\frac{n\varepsilon^2}{H^2}}.
        \end{align*}
        Using the same approach above,
        \begin{align*}
        \proba{\neg\event_1} 
        &=\proba{\exists x,a, t'\le t,|\rbar_{t'}(x,a)-r(x,a)+(\Pbar_{t'}(x,a)-P(x,a))f| >H\sqrt{\frac{L_t}{2N_{t'}(x_a)}}} \\
        &\le2\sum_{x,a} \sum_{t'=1}^{t}e^{-\log(4E^2At/\delta)} =2EAt\frac{\delta}{4E^2At}=\frac{\delta}{2E}
        \end{align*}
        Given $\{U_i\}_{1\le i\le n}$ independent samples of random variable $U\in[0, c]$ where $c\in\R$ and $\var{U}=\sigma^2$, Bernstein inequality gives
        \begin{align*}
        \proba{|\bar{U}-\ex{U}|> \varepsilon} \le 2e^{-\frac{n\varepsilon^2}{2\sigma^2+\frac{2c}3\varepsilon}}
        \end{align*}
        Consider a fixed $(x,a,y)$. For any deterministic mapping $g\colon\mcal{E}\mapsto[0,H]$, let $U:=g(Y)$ be a random variable and $Y\in\mcal{E}$ where $\proba{Y=y}=P(x,a,y)$.
        So, we have
        \begin{align*}
        \ex{U}=P(x,a,y)g(y),\ \var{U}=P(x,a,y)(1-P(x,a,y))g^2(y):=\sigma^2(y), \text{ and } U\in[0,H].
        \end{align*}
        Then,
        \begin{align*}
        \proba{\neg\event_2}
        &=\proba{\exists x,a,y,t'\le t,|\Pbar_{t'}(x,a,y)-P(x,a,y)|g(y) >\sqrt{\frac{2\sigma^2(y)L_t}{N_{t'}(x,a)}} +\frac{2HL_t}{3N_{t'}(x,a)}} \\
        &\le\sum_{x,a,y} \sum_{t'=1}^{t} \proba{|\Pbar_{t'}(x,a,y)-P(x,a,y)|g(y) \le\sqrt{\frac{2\sigma^2(y)L_t}{N_{t'}(x,a)}} +\frac{2HL_t}{3N_{t'}(x_a)}\mid N_{t'}(x_a)=n} \\
        &\le E^2At 2\exp\left(-\frac{n\left(\sqrt{\frac{2\sigma^2(y)L_t}{n}} +\frac{2HL_t}{3n}\right)^2}{2\sigma^2(y)+\frac{2H}{3}\left(\sqrt{\frac{2\sigma^2(y)L_t}{n}} +\frac{2HL_t}{3n}\right)}\right) \\
        &\le 2E^2At\exp\left(-\frac{n\left[\frac{2\sigma^2(y)L_t}{n} +\frac{2HL_t}{3n}\left(\sqrt{\frac{2\sigma^2(y)L_t}{n}} +\frac{2HL_t}{3n}\right)\right]}{2\sigma^2(y)+\frac{2H}{3}\left(\sqrt{\frac{2\sigma^2(y)L_t}{n}} +\frac{2HL_t}{3n}\right)}\right) \\
        &=2E^2At\exp(-\log(4E^2At/\delta)) = \frac{\delta}2
        \end{align*}
        Now,
        \begin{align*}
        \proba{\neg\event} 
        &\le\proba{\neg\event_1} +\proba{\neg\event_2}\le\frac{\delta}{2E} +\frac{\delta}2\le \delta\frac{1+E}{2E} \le \delta.
        \end{align*}
        \end{proof}
        
        \begin{lem}
        \label{lem:bern}
        Under event $\event$, for any $g\colon\mcal{E}\mapsto[0,H]$ and any $x,a$,
        \begin{align*}
        \vert (\Pbar_t(x,a)-P(x,a))g \vert
        \le \frac1H\ex{g(Y) \mid Y\sim P(x,a)} +\frac{SH^2L_t}{N_t(x,a)}
        \end{align*}
        \end{lem}
        \begin{proof}
        \begin{align*}
        \vert (\Pbar_t(x,a)-P(x,a))g \vert
        &= \vert\sum_{y\in\mcal{E}}\big(\Pbar_t(x,a,y) -P(x,a,y)\big)g(y)\vert \\
        &\le \sum_{y\in\mcal{E}}|\Pbar_t(x,a,y) -P(x,a,y)|g(y) \\
        &\overset{(a)}{\le} \sum_{y\in\mcal{E}} \sqrt{\frac{2P(x,a,y)[1-P(x,a,y)]g^2(y)L_t}{N_t(x,a)}} +\sum_{y\in\mcal{E}}\frac{2HL_t}{3N_t(x,a)} \\
        &\le \sum_{y\in\mcal{E}} \sqrt{\frac{2P(x,a,y)g^2(y)L_t}{N_t(x,a)}} +\frac{2EHL_t}{3N_t(x,a)} \\
        &\overset{(b)}{\le}\sqrt{E}\sqrt{\frac{2L_t}{N_t(x,a)} \sum_{y\in\mcal{E}}P(x,a,y)g^2(y)} +\frac{2EHL_t}{3N_t(x,a)} \\
        &=\sqrt{\frac{2EH^2L_t}{N_t(x,a)} \sum_{y\in\mcal{E}}P(x,a,y)\frac{g^2(y)}{H^2}} +\frac{2EHL_t}{3N_t(x,a)} \\
        &\overset{(c)}{\le}\frac{EH^2L_t}{N_t(x,a)} +\sum_{y\in\mcal{E}}P(x,a,y)\frac{g^2(y)}{H^2} +\frac{2EHL_t}{3N_t(x,a)} \\
        &\overset{(d)}{\le} \sum_{y\in\mcal{E}}P(x,a,y)\frac{g(y)}{H} +\frac{EH^2L_t}{N_t(x,a)}\\
        &=\frac1H\ex{g(Y) \mid Y\sim P(x,a)} +\frac{EH^2L_t}{N_t(x,a)} 
        \end{align*}
        where $(a)$ is true under the event $\xi$, $(b)$ is true due to Cauchy-Schwartz inequality, $(c)$ is true due to $ab\le(a^2+b^2)/2$ and $(d)$ is true due to $g\le H$.
        \end{proof}
        
        \begin{lem}
        \label{lem:bonus}
        Let $L_t:=\log(4E^2At/\delta)$. For any $x,a$, define $b(x,a):=H\sqrt{\frac{L_t}{2N_t(x,a)}}$.
        Let $\mTilde:=\langle\mcal{E}, [n], \rhat+b, \Phat\rangle$ be a MDP and $V_{\mTilde}^{*}$ be the optimal value function in $\mTilde$.
        Under event $\event$, $$V_{\mTilde}^{*} \ge V_M^*.$$
        \end{lem}
        \begin{proof}
        Let $\pik$ be the policy used during episode $k$. By Bellman, we have
        \begin{align*}
        V_{k,h}(x)
        &= \rbar(x,\pik(x)) +b(x,\pik(x)) +\Pbar(x,\pik(x)) V_{k,h+1} \\
        &\ge \rbar(x,\pi_*(x)) +b(x,\pi_*(x)) +\Pbar(x,\pi_*(x)) V_{k,h+1}.
        \end{align*}
        Then,
        \begin{align*}
        V_{k,h}(x) -V_{M,h}^{*}(x)
        &= \rbar(x,\pik(x)) +b(x,\pik(x)) +\Pbar(x,\pik(x)) V_{k,h+1} 
        -r(x,\pi_*(x)) -P(x,\pi_*(x))V_{M,h+1}^{*} \\
        &\ge \rbar(x,\pi_*(x)) +b(x,\pi_*(x)) +(\Pbar(x,\pi_*(x)) V_{k,h+1}
        -r(x,\pi_*(x)) -P(x,\pi_*(x))V_{M,h+1}^{*} \\
        &= b(x,\pi_*(x)) +(\rbar-r)(x,\pi_*(x)) +[(\Pbar-P)V_{M,h+1}^{*}](x,\pi_*(x)) +\Pbar(x,\pi_*(x))(V_{k,h+1} -V_{M,h+1}^{*}).
        \end{align*}
        For $h=H$, we have $V_{k,H}(x) -V_{M,h}^*(x) \ge b(x,\pi_*(x)) +(\rbar-r)(x,\pi_*(x)) \ge0$ where the last inequality is true under event $\event_k$.
        Suppose that $V_{k,h}\ge V_{M,h}^*$ is true for $h=\{h+1,\dots,H\}$.
        We prove that $V_{k,l}\ge V_{M,l}^*$ is also true for $l=h$.
        We have
        \begin{align*}
        V_{k,h}(x) -V_{M,h}^{*}(x)
        &\ge b(x,\pi_*(x)) +(\rbar-r)(x,\pi_*(x)) +[(\Pbar-P)V_{M,h+1}^{*}](x,\pi_*(x)) +\Pbar(x,\pi_*(x))(V_{k,h+1} -V_{M,h+1}^{*}) \\
        &\ge b(x,\pi_*(x)) +(\rbar-r)(x,\pi_*(x)) +[(\Pbar-P)V_{M,h+1}^{*}](x,\pi_*(x)) \ge0.
        \end{align*}
        where the last inequality is true, again, under event $\event_k$.
        \end{proof}
    
    \subsection{Regret bound}
    \label{subsec:regret_ucbvi}
    
    Let $b_k:=H\sqrt{\log(4E^2At_k/\delta)/(2N_k)}$. Under $\event_k$, Lemma~\ref{lem:bonus} implies that $V_M^*-V_M^{\pik} \le V_{k}-V_M^{\pik}$.
    Then,
    \begin{align*}
    V_{k,1}(x_{k1}) -V_{M,1}^{\pik}(x_{k1})
    &=\rbar_k(x_{k1},a_{k1}) +\Pbar_k(x_{k1},a_{k1})V_{k,2} +b_k(x_{k1},a_{k1}) -r(x_{k1},a_{k1}) -P(x_{k1},a_{k1})V_{M,2}^{\pik} \\
    &=\rbar_k(x_{k1},a_{k1}) -r(x_{k1},a_{k1}) +(\Pbar_k(x_{k1},a_{k1}) -P(x_{k1},a_{k1}))V_{M,2}^*
    \end{align*}
    Since $\Pbar V_k -PV_M^{\pik}=(\Pbar-P)V_M^* +P(V_k-V_M^{\pik}) +(\Pbar-P)(V_k-V_M^*)$, we have
    \begin{align*}
    V_{k,1}(x_{k1}) -V_{M,1}^{\pik}(x_{k1})
    &=\underbrace{\rbar_k(x_{k1},a_{k1}) -r(x_{k1},a_{k1}) +(\Pbar_k(x_{k1},a_{k1}) -P(x_{k1},a_{k1}))V_{M,2}^*}_{I_1} +b_k(x_{k1},a_{k1}) \\
    &\qquad +P(x_{k1},a_{k1})(V_{k,2}-V_{M,2}^{\pik}) +\underbrace{(\Pbar_k(x_{k1},a_{k1})-P(x_{k1},a_{k1}))(V_{k,2}-V_{M,2}^*)}_{I_2}.
    \end{align*}
    Under $\event_k$, we have
    \begin{align*}
    I_1&\le H\sqrt{\frac{L_{t_k}}{2N_k(x_{k1},a_{k1})}}
    \end{align*}
    by when taking $f=V_{M,2}^{*}$ under event $\event_k$.
    Also, by Lemma~\ref{lem:bern} with $g=V_{k,2} -V_{M,2}^{*}$,
    \begin{align*}
    I_2
    &\le\frac1{H}\ex{V_{k,2}(Y) -V_{M,2}^{*}(Y) \mid Y\sim P(x_{k1}, a_{k1})} +\frac{EH^2L_{t_k}}{N_k(x,a)} \\
    &\le\frac1{H}\ex{V_{k,2}(Y) -V_{M,2}^{\pik}(Y) \mid Y\sim P(x_{k1}, a_{k1})} +\frac{EH^2L_{t_k}}{N_k(x,a)}
    \end{align*}
    where the last inequality is true due to $V^*_M\ge V^{\pik}_{M}$.
    Then,
    \begin{align*}
    V_{k,1}(x_{k1}) -V_{M,1}^{\pik}(x_{k1})
    &\le b_k(x_{k1},a_{k1}) +H\sqrt{\frac{L_{t_k}}{2N_k(x_{k1},a_{k1})}} +\frac{EH^2L_{t_k}}{N_k(x_{k1},a_{k1})} \\
    &\qquad +\left(1+\frac1H\right)\ex{V_{k,2}(Y) -V_{M,2}^{\pik}(Y) \mid Y\sim P(x_{k1}, a_{k1})}
    \end{align*}
    Continue to rollout $V_{k,h}-V_{M,h}^{\pik}$, we get
    \begin{align*}
    \ex{V_{k,1}(x_{k1})-V_{M,1}^{\pik}(x_{k1})}
    &\le\sum_{t=t_k}^{t_{k+1}-1}\underbrace{\left(1+\frac1H\right)^{t-t_k}}_{\le e} \left(2H\sqrt{\frac{L_{t_k}}{2N_k(x_t,a_t)}} +\frac{EH^2L_{t_k}}{N_k(x_t,a_t)}\right).
    \end{align*}
    Then, the upper bound of expected regret of UCBVI is
    \begin{align*}
    \ex{\Reg(T,\mathrm{UCBVI},M)}
    &\le e\sum_{k=1}^{\lceil T/H\rceil}\sum_{t=t_k}^{t_{k+1}-1}  \left(H\sqrt{\frac{2L_{t_k}}{N_k(x_t,a_t)}} +\frac{EH^2L_{t_k}}{N_k(x_t,a_t)}\right) +T\delta \\
    &\le e\sum_{k=1}^{\lceil T/H\rceil}\sum_{t=t_k}^{t_{k+1}-1}  \left(H\sqrt{\frac{2L_T}{N_k(x_t,a_t)}} +\frac{EH^2L_T}{N_k(x_t,a_t)}\right) +T\delta
    \end{align*}
    Using the same approach to bound $\sum_{k=1}^{\lceil T/H\rceil}\sum_{t=t_k}^{t_{k+1}-1}[1/\sqrt{N_k(x_t,a_t)} +1/N_k(x_t,a_t)]$,
    the expected regret is roughly upper bounded by $\tilde{O}\left(H\sqrt{EAT}\right)$.

\section{PSRL}
\label{sec:psrl}

\subsection{Statistical Inference}
\label{subsec:statistical_inf}

Before presenting the algorithms, we want to review some interesting points in Statistical Inference that are related to our problem.

Consider a statistical parametric model $\mathfrak{M}=\{p(\cdot|\theta);\theta\in\Theta\}$ where $\theta$ is a parameter of the model living in the parameter space $\Theta$, and $p(\cdot|\theta)$ is the probability measure of an event in function of the parameter $\theta$.

- for discrete random variable X, we write $p(x|\theta)=\mathbb{P}_{\theta}\{X=x\}$
- for continuous random variable X, we write $p(x|\theta)=f(x;\theta)$ where $f(x;\theta)$ is the (probability) density function

We want to estimate the parameter of the model, $\theta$, using the observations. Suppose that we have

- $(X_1,\dots,X_n)\rightarrow(x_1,\dots,x_n)$: $n$ observations sampled from the model
- each observation is independent from one another

To infer the parameter, there are two perspectives: frequentist and bayesian.

\subsubsection{Frequentist perspective}
\label{subsubsec:freq_perspective}

One idea in frequentist perspective is to write a likelihood or log-likelihood in function of $\theta$ and observations $(x_1,\dots,x_n)$, then choose $\hat{\theta}$ that maximizes the likelihood:

\begin{align*}
l_{(x_1,\dots,x_n)}(\theta)&=\prod_{i=1}^{n}p(x_i|\theta) \\
L_{(x_1,\dots,x_n)}(\theta)&=\sum_{i=1}^{n}\log p(x_i|\theta)
\end{align*}

and $$\hat{\theta}=\arg\max_{\theta\in\Theta}l_{(x_1,\dots,x_n)}(\theta)=\arg\max_{\theta\in\Theta}L_{(x_1,\dots,x_n)}(\theta)$$

\subsubsection{Bayesian perspective}
\label{subsubsec:bayes_perspective}

One idea in this perspective is to derive the distribution of the parameter $\theta$ then draw the parameter from that distribution when needed. Concretely, we put a Prior distribution on the parameter $\theta$, use the observations to deduce the Posterior distribution, and sample the parameter $\hat{\theta}$ from the Posterior.

- we make a hypothesis that the parameter has a certain distribution $p(\theta)$
- the Likelihood of the observations: $l_{(x_1,\dots,x_n)}(\theta)=\prod_{i=1}^{n}p(x_i|\theta)$
- from Bayes's theorem: $$p(\theta|x_1,\dots,x_n) =\frac{l_{(x_1,\dots,x_n)}(\theta)p(\theta)}{p(x_1,\dots,x_n)} \propto l_{(x_1,\dots,x_n)}(\theta)p(\theta)$$
- when needed, we draw $\hat{\theta}\sim l_{(x_1,\dots,x_n)}(\theta)p(\theta)$

\subsection{Application of Posterior Sampling}

We make a hypothesis that the unknown $\mdpModel$ is drawn from a distribution $\phi(\mdpModel)$. It is our \textbf{prior distribution} about the MDP. So, we draw a MDP from that distribution, compute the respective optimal policy and play that policy in $\mdpModel$ for a whole episode to collect observations. Then, we refine our prior distribution based on Bayes' theorem and the observations collected. The refined distribution is called \textbf{posterior distribution}.

Concretely, let $\mcal{O}_k$ be the observations collected overall episodes until time step $1$ of $k$th episode. So, the algorithm $\mathrm{PSRL}$ draws $M_k$ from the posterior distribution $\phi(\cdot|\mcal{O}_k)$, computes the optimal policy $\pik$ in that MDP and uses $\pik$ during the $k$th episode.

\subsection{Bayesian Regret}
\label{subsec:regret_psrl}

In this section, we study the bayesian regret in posterior sampling approach and prove its bound when using PSRL algorithm. Suppose that the unknown MDP $M$ is drawn from $\phi$. The bayesian regret is defined by

$$\BayReg(T,\mathrm{PSRL})=\mathbb{E}\left[\Reg(T,\mathrm{PSRL},M) |M\sim\phi\right]$$

where $\Reg(T,\mathrm{PSRL},M)$ is defined in Equation$~\eqref{eq:eq_6}$. After playing $(k-1)$ episodes and collecting $\mcal{O}_{k}$, we believe that $M$ is drawn from the posterior distribution $\phi(\cdot|\mcal{O}_{k})$. So, $M$ and $M_k$ have the same distribution and for any $\sigma(\mcal{O}_{k})$-measurable function $f$, we have
\begin{align*}
\mathbb{E}[f(M)|\mcal{O}_{k}] =\mathbb{E}[f(M_k)|\mcal{O}_{k}]
\end{align*}
and applying the law of total expectation, we get $\mathbb{E}[f(M)] =\mathbb{E}[f(M_k)]$. This implies that $\mathbb{E}[\Delta_k^{opt}]=0$. Effectively, $\Delta_k^{opt}=V^*_{M,1}(x) -V^{\pik}_{M_k,1}(x)$ where the optimal value $V^*_M$ is a $\sigma(\mcal{O}_{k})$-measurable function of $M$ and the optimal value $V^{\pik}_{M_k}$ is a $\sigma(\mathcal{O}_{k})$-measurable function of $M_k$.

So, we get
\begin{align*}
\BayReg(T,\mathrm{PSRL}) =\ex{\sum_{k=1}^{\lceil T/H\rceil}\Delta_k^{conc} |M\sim\phi}
\end{align*}
Following the same approach in the prove of UCRL2, we get the upper bound of Bayesian regret of PSRL as $O(HE\sqrt{AT})$.
    
