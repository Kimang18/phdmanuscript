Markovian bandits are a subclass of multi-armed bandit problems in which each arm has an internal state that evolves over time in a Markovian manner depending on the decision maker's actions. 
