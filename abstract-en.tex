Markovian bandits are a subclass of multi-armed bandit problems in which each arm has an internal state that evolves in a Markovian manner depending on the decision maker's actions. 
