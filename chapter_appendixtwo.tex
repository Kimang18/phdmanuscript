\begingroup

\let\clearpage\relax
\chapter{Learning Algorithms}
\label{chp:apx_learning}

The appendix are organized as follows:
\begin{itemize}
    \item In Appendix~\ref{apx:proof_thm1}, we prove Theorem~\ref{thm:regret_upper_bound}. 
    \item In Appendix~\ref{apx:sketch_of_proof_lower}, we obtain a Bayesian minimax regret lower bound for any reinforcement learning algorithm in Markovian bandits (Theorem~\ref{thm:lower_bound}).
    \item In Appendix~\ref{apx:proof_OFU}, we show that \Eqref{eq:EVI} cannot be solved by local indices (Theorem~\ref{thm:no_OFU}).
    \item In Appendix~\ref{apx:algos}, we provide a detailed description of the algorithms that we use in our numerical comparisons. 
    \item In Appendix~\ref{apx:add_numerical}, we provide additional numerical experiments that show the good behavior of MB-PSRL. 
    \item In Appendix~\ref{apx:envi}, we provide details about the experimental environment and the computation time needed. 
\end{itemize}


\endgroup


