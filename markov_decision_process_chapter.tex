\chapter{Markov Decision Process}
\label{ch:mdp}

In this section, we are about to decribe what is a Markov decision process and quantities used.

\section{Definition and Notations}

\begin{enumerate}
    \item what is a MDP: $<++>$ <++>
\end{enumerate}

\section{Settings}

Different settings of MDP.

\subsection{Finite horizon}

Maybe?

\subsection{Dicounted infinite horizon}

The reward is discounted with discount factor $\beta$.

\subsection{Average reward criteria}

Optimality equation
